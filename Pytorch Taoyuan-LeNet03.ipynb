{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvNeuron():\n",
    "    def __init__(self,kernel_size,padding_size,learning_rate):\n",
    "        self.kernel_size=kernel_size # kernel_size: n -> means n*n \n",
    "        self.padding_size=padding_size # padding_size:n , image width:w , image height:h -> w=w+2n,h=h+2n\n",
    "        self.padded_input\n",
    "        self.lr=learning_rate\n",
    "        self.weight_initialize() # initalize weights and bias\n",
    "        \n",
    "    def weight_initialize(self):\n",
    "        self.Kernel=np.random.random([self.kernel_size,self.kernel_size])# Kernel: [n,n] size np array,randomly initialize\n",
    "        self.bias=np.random.random(1) # bias : scalar \n",
    "        \n",
    "    def Padding(self,input_data):\n",
    "        H,W=input_data.shape # H as height of image, W as width of image\n",
    "        self.input_data=input_data\n",
    "        x=input_data \n",
    "        for i in range(self.padding_size):  #from 0 to self.padding_size\n",
    "            x=np.insert(x,W+i*2,0,axis=1)  # np.insert(array,index_,valuse,axis_dimension): add 0 to column W+i\n",
    "            x=np.insert(x,0,0,axis=1)      # as above\n",
    "            \n",
    "        \n",
    "        for j in range(self.padding_size): #from 0 to self.padding_size\n",
    "            x=np.insert(x,H+j*2,0,axis=0) # add 0 array to row H+j\n",
    "            x=np.insert(x,0,0,axis=0)     # add 0 array to row 0\n",
    "            \n",
    "        self.padded_input=x\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Forward(self,input_data): \n",
    "        #forward operation of convolutional neuron\n",
    "        L,W=input_data.shape  # get shap of data: L :length(height), W:width\n",
    "        k=self.kernel_size    #kernel size\n",
    "        output=np.zeros([L-k+1,W-k+1])    #declare output size array\n",
    "        \n",
    "        #operation of convolution~~~~~~~\n",
    "        for i in range(L-k+1):            \n",
    "            for j in range(W-k+1):\n",
    "                for ii in range(k):\n",
    "                    for jj in range(k):\n",
    "                        output[i,j]+=input_data[i+ii,j+jj]*self.Kernel[ii,jj]\n",
    "        output+=self.bias\n",
    "        #end of convolution--------\n",
    "        return output\n",
    "    \n",
    "    def Backward(self,errors):\n",
    "        #errors from downstream layer,add each error,\n",
    "        E=np.sum(errors,axis=0) #add each error\n",
    "        #calculate and update weights\n",
    "        L,W=E.shape\n",
    "        grid_k=np.zeros((L,W))#restore gradient of kernel errors\n",
    "        grid_b=E.sum() # bias is the sum of error matrix\n",
    "        \n",
    "        #calculate gradient of kernel error\n",
    "        for i in range(L):\n",
    "            for j in range(W):\n",
    "                grid_k[i,j]+=E[i,j]*self.padded_input[i:i+L][j:j+W]\n",
    "        \n",
    "        #calculate error back to upstream layer, size is as the input data size \n",
    "        # it is more complicated, because not \n",
    "        H,N=self.input_data.shape\n",
    "        grid_E=np.zeros((H,N))\n",
    "        k=self.kernel_size\n",
    "        for i in range(H):\n",
    "            for j in range(N):\n",
    "                for x in range(k):\n",
    "                    for y in range(k):\n",
    "                        if i-x>=0 and j-y>=0 and i-x+(k-1)<=L and j-y+(k-1)<=W:\n",
    "                            grid_E[i,j]+=E[i-x,j-y]*self.Kernel[x,y]\n",
    "        \n",
    "        #update weights\n",
    "        self.bias-=self.lr*grid_b\n",
    "        self.Kernel-=self.lr*grid_k\n",
    "        \n",
    "        return grid_E\n",
    "        \n",
    "\n",
    "    def __call__(self, input_data):\n",
    "        '''\n",
    "        it is an useful internal function to make coding simpler.\n",
    "        e.g.\n",
    "        no __call__ :\n",
    "        \n",
    "        a=ConvNeuron(5,5)\n",
    "        x=a.operationA(input)\n",
    "        x=a.operationB(x)\n",
    "        x=a.operationC(x)\n",
    "        \n",
    "        with __call__ :\n",
    "        first define __call__,\n",
    "        \n",
    "        def __call__(self,x):\n",
    "            x=self.operationA(x)\n",
    "            x=self.operationB(x)\n",
    "            x=self.operationC(x)\n",
    "            return x\n",
    "        \n",
    "        a=ConvNeuron(5,5)\n",
    "        x=a(input)       \n",
    "        '''\n",
    "        #return self.Forward(input_data)\n",
    "        x=self.Padding(input_data)\n",
    "        x=self.Forward(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.45213594e-01 8.70932158e-01 4.60712836e-02 6.04758485e-01\n",
      "  6.26508387e-01 1.35672658e-01]\n",
      " [4.98523080e-01 9.08997436e-01 8.79399392e-01 7.35847317e-01\n",
      "  2.86887415e-01 5.71218045e-02]\n",
      " [4.54462515e-01 4.23062327e-04 1.56329115e-02 7.78179040e-01\n",
      "  2.60473090e-01 1.21192102e-02]\n",
      " [5.98186068e-01 3.25081532e-01 9.91946803e-01 2.68192256e-01\n",
      "  6.00901554e-01 8.53186507e-01]\n",
      " [3.44589111e-01 4.60773897e-01 9.64092084e-01 8.00579432e-01\n",
      "  9.87519083e-01 9.16302623e-01]\n",
      " [9.20849398e-01 5.53985826e-01 6.33715851e-02 9.51130779e-01\n",
      "  2.21202090e-01 4.36522696e-01]]\n",
      "[[0.55018287 0.49104987 0.48501243]\n",
      " [0.55463882 0.53210439 0.45900185]\n",
      " [0.66103378 0.54204636 0.63267511]]\n"
     ]
    }
   ],
   "source": [
    "class PoolingNeuron():\n",
    "    def __init__(self,learning_rate):\n",
    "        self.weight_initialize()\n",
    "        self.lr=learning_rate\n",
    "    def weight_initialize(self):\n",
    "        self.bias=np.random.random(1)# only bias here\n",
    "        \n",
    "    def Forward(self,input_data):\n",
    "        L,W=input_data.shape   #get shape of data L:length, W:width\n",
    "        a=int(L/2)\n",
    "        b=int(W/2)\n",
    "        output=np.zeros([a,b]) # create zero array of size[a,b]\n",
    "        \n",
    "        #pooling operation----\n",
    "        for i in range(a):\n",
    "            for j in range(b):\n",
    "                output[i,j]=np.mean([input_data[i*2,j*2:j*2+1],input_data[i*2+1,j*2:j*2+1]])\n",
    "        output+=self.bias\n",
    "        #end of pooling operation----\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def Backward(self,errors):\n",
    "        #errors from downstream layer,add each error,\n",
    "        E=np.sum(errors,axis=0) #add each error\n",
    "        #calculate and update weights\n",
    "        L,W=E.shape\n",
    "        grid_b=E.sum() # bias is the sum of error matrix\n",
    "        \n",
    "        H,N=self.input_data.shape\n",
    "        \n",
    "        grid_E=np.zeros((H,N))\n",
    "        for i in range(H):\n",
    "            for j in range(N):\n",
    "                grid_E=E[i/2,j/2]/4\n",
    "        \n",
    "        self.bias-=self.lr*grid_b\n",
    "        return grid_E\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def __call__(self,input_data):\n",
    "        return self.Forward(input_data)\n",
    "\n",
    "\n",
    "b=PoolingNeuron(0.02)\n",
    "x=np.random.random([6,6])\n",
    "print(x)\n",
    "y=b(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55734612 0.14214896 0.9368311  0.82243537 0.20284664 0.59177475\n",
      " 0.89607881 0.20989387 0.19735711 0.12439078]\n",
      "[2.43029819]\n"
     ]
    }
   ],
   "source": [
    "class ScalarNeuron():\n",
    "    def __init__(self,input_size,learning_rate):\n",
    "        #multiple scalar inputs,or see them as plenty of [1x1] array is also ok.\n",
    "        self.input_size=input_size #define input size\n",
    "        self.weight_initialize()\n",
    "        self.lr=learning_rate\n",
    "        \n",
    "    def weight_initialize(self):\n",
    "        self.weights=np.random.random([self.input_size]) # same as input size, or how many scalar inputs\n",
    "        self.bias=np.random.random(1) # only 1 bias\n",
    "    \n",
    "    def Forward(self,input_data):        \n",
    "        y=np.multiply(input_data,self.weights) #elementwise multiply output size is [self.input_size]\n",
    "        y=np.sum(y)+self.bias # output is scalar.\n",
    "        return y\n",
    "    def Backward(self,errors):\n",
    "        E=np.sum(errors,axis=0) #add each error\n",
    "        grid_w=np.ones(self.weights.shape)\n",
    "        grid_b=1.0\n",
    "        grid_E=np.zeros(self.input_size)\n",
    "        \n",
    "        for i in range(self.input_size):\n",
    "            grid_E[i]=self.weights[i]\n",
    "        \n",
    "        #update weights\n",
    "        self.bias-=self.lr*grid_b\n",
    "        self.weights-=self.lr*grid_w\n",
    "        \n",
    "        return grid_E\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def __call__(self,input_data):\n",
    "        return self.Forward(input_data)\n",
    "\n",
    "Size=10    \n",
    "L=ScalarNeuron(Size,0.02)\n",
    "x=np.random.random([Size])\n",
    "print(x)\n",
    "y=L(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
